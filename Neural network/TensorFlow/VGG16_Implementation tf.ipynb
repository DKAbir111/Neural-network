{"cells":[{"cell_type":"markdown","metadata":{"id":"t6Si5J5XNmND"},"source":["# **Import Libraries**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6Aw1fKaYist"},"outputs":[],"source":["import numpy as np\n","import keras\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n","from keras.models import Sequential, load_model\n","from keras.optimizers import Adam\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","\n","from keras.saving import hdf5_format\n","from keras.saving import saving_utils\n","from keras.saving.saved_model import load as saved_model_load\n","from keras.saving.saved_model import load_context\n","from keras.saving.saved_model import save as saved_model_save"]},{"cell_type":"markdown","metadata":{"id":"yg4_PN1EOJgE"},"source":["# **Import Zip file from local device and unzip the file**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":39},"id":"ixK1sqyQdCb1","outputId":"253a0bf0-edc0-4077-ac6b-683c81f0507f"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-4b757921-5a36-4360-b664-b065239f8771\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-4b757921-5a36-4360-b664-b065239f8771\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxOsRqVaZ5VG"},"outputs":[],"source":["#unzip the training data\n","\n","from zipfile import ZipFile\n","file_name = \"/content/training_set.zip\"\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print('Done')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eg-prfGtvRKP"},"outputs":[],"source":["#unzip the test data\n","\n","from zipfile import ZipFile\n","file_name1 = \"/content/test_set.zip\"\n","\n","with ZipFile(file_name1, 'r') as zip1:\n","  zip1.extractall()\n","  print('Done')"]},{"cell_type":"markdown","metadata":{"id":"BLYZwjgGOcRi"},"source":["# **Train data and Test data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1299,"status":"ok","timestamp":1673636582140,"user":{"displayName":"Nasima Islam Bithi","userId":"07730572757890972820"},"user_tz":-360},"id":"MfWafiq7bP8F","outputId":"e2b47b9d-ec30-4bd9-9f3a-c6a2d5e1be61"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8005 images belonging to 2 classes.\n"]}],"source":["trdata=ImageDataGenerator()\n","traindata=trdata.flow_from_directory(directory=\"/content/drive/MyDrive/DL course/training_set\", \n","target_size=(224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4857,"status":"ok","timestamp":1673636606786,"user":{"displayName":"Nasima Islam Bithi","userId":"07730572757890972820"},"user_tz":-360},"id":"XH8VkpKGe-4x","outputId":"c14f7d4b-a15a-43a9-f11a-ff7112d2f664"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2023 images belonging to 2 classes.\n"]}],"source":["tsdata=ImageDataGenerator()\n","testdata=tsdata.flow_from_directory(directory=\"/content/drive/MyDrive/DL course/test_set\", \n","target_size=(224,224))"]},{"cell_type":"markdown","metadata":{"id":"t41oYk25PdQA"},"source":["# **Model Generation**"]},{"cell_type":"markdown","metadata":{"id":"RASgdBYBRtzD"},"source":["**Sequential Layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgL0wJlufKdk"},"outputs":[],"source":["model= Sequential()"]},{"cell_type":"markdown","metadata":{"id":"d8HMp5_LR4LI"},"source":["**Convolution layer and Max pooling layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FwKZ9KAzeyA5"},"outputs":[],"source":["#input layer\n","model.add(Conv2D(input_shape=(224,224,3),filters=64, kernel_size=(3,3),\n","                 padding='same',activation='relu')) \n","#Hidden layer\n","model.add(Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jR6tVPO8f8VC"},"outputs":[],"source":["model.add(Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lgk9H7nhDxv"},"outputs":[],"source":["model.add(Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GFXVx3XPhRw_"},"outputs":[],"source":["model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZjEPuH-hbYY"},"outputs":[],"source":["model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(Conv2D(filters=512, kernel_size=(3,3),padding='same',activation='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"]},{"cell_type":"markdown","metadata":{"id":"sE0CLZ2bSUKs"},"source":["**Output Layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaIzkHEHhlQg"},"outputs":[],"source":["model.add(Flatten())\n","model.add(Dense(units=4096,activation='relu')) #fully connected layer\n","model.add(Dense(units=4096,activation='relu'))\n","model.add(Dense(units=2,activation='softmax')) # number of output class is 2"]},{"cell_type":"markdown","metadata":{"id":"Y6-t_tabS6bw"},"source":["# **Model Compilation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6S4KDP95hsIH"},"outputs":[],"source":["#optimizer, loss function and accuracy metrics\n","opt=Adam(learning_rate=.001)\n","model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy,\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1673636632840,"user":{"displayName":"Nasima Islam Bithi","userId":"07730572757890972820"},"user_tz":-360},"id":"21FJQZeTh0na","outputId":"36a48b39-25a2-4d3a-c34e-a6ccc74e0f2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              102764544 \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 8194      \n","                                                                 \n","=================================================================\n","Total params: 134,268,738\n","Trainable params: 134,268,738\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y81cp91Mh49N"},"outputs":[],"source":["checkpoint=ModelCheckpoint(\"/content/drive/MyDrive/DL course/ModelFiles\", monitor='val_acc',\n","                           verbose=1, save_best_only=True,\n","                           save_weights_only=False, mode='auto',\n","                           save_freq=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zG5PQVbSiH7o"},"outputs":[],"source":["earlystop= EarlyStopping(monitor='val_acc', min_delta=0, patience=20, \n","                         verbose=1,mode='auto')"]},{"cell_type":"markdown","metadata":{"id":"mJx8bcVUTnRc"},"source":["# **Model Fitting**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MQ9AqWiSiKrB"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-16-a09e97de3b02\u003e:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  hist=model.fit_generator(steps_per_epoch=10, generator=traindata,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\r 1/10 [==\u003e...........................] - ETA: 11:43 - loss: 0.6932 - accuracy: 0.5000"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 2/10 [=====\u003e........................] - ETA: 7:47 - loss: 0.6923 - accuracy: 0.5469 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 3/10 [========\u003e.....................] - ETA: 6:40 - loss: 0.6918 - accuracy: 0.5729"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 4/10 [===========\u003e..................] - ETA: 5:45 - loss: 0.6920 - accuracy: 0.5625"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 5/10 [==============\u003e...............] - ETA: 4:46 - loss: 0.6924 - accuracy: 0.5437"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 6/10 [=================\u003e............] - ETA: 3:51 - loss: 0.6929 - accuracy: 0.5208"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 7/10 [====================\u003e.........] - ETA: 2:53 - loss: 0.6936 - accuracy: 0.4911"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 8/10 [=======================\u003e......] - ETA: 1:55 - loss: 0.6933 - accuracy: 0.5039"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 9/10 [==========================\u003e...] - ETA: 57s - loss: 0.6929 - accuracy: 0.5243 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5250 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - 749s 75s/step - loss: 0.6929 - accuracy: 0.5250 - val_loss: 0.6938 - val_accuracy: 0.4688\n","Epoch 2/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\r 1/10 [==\u003e...........................] - ETA: 9:39 - loss: 0.6893 - accuracy: 0.6875"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 2/10 [=====\u003e........................] - ETA: 7:36 - loss: 0.6894 - accuracy: 0.6719"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 3/10 [========\u003e.....................] - ETA: 6:51 - loss: 0.6904 - accuracy: 0.6250"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 4/10 [===========\u003e..................] - ETA: 5:46 - loss: 0.6916 - accuracy: 0.5781"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 5/10 [==============\u003e...............] - ETA: 4:48 - loss: 0.6913 - accuracy: 0.5813"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 6/10 [=================\u003e............] - ETA: 3:49 - loss: 0.6911 - accuracy: 0.5833"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 7/10 [====================\u003e.........] - ETA: 2:51 - loss: 0.6913 - accuracy: 0.5759"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 8/10 [=======================\u003e......] - ETA: 1:54 - loss: 0.6922 - accuracy: 0.5508"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 9/10 [==========================\u003e...] - ETA: 56s - loss: 0.6922 - accuracy: 0.5486 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5531 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - 727s 74s/step - loss: 0.6919 - accuracy: 0.5531 - val_loss: 0.6957 - val_accuracy: 0.4500\n","Epoch 3/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\r 1/10 [==\u003e...........................] - ETA: 10:05 - loss: 0.6934 - accuracy: 0.5000"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 2/10 [=====\u003e........................] - ETA: 7:24 - loss: 0.6949 - accuracy: 0.4688 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 3/10 [========\u003e.....................] - ETA: 6:34 - loss: 0.6939 - accuracy: 0.4896"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 4/10 [===========\u003e..................] - ETA: 5:36 - loss: 0.6918 - accuracy: 0.5312"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 5/10 [==============\u003e...............] - ETA: 4:39 - loss: 0.6941 - accuracy: 0.5125"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 6/10 [=================\u003e............] - ETA: 3:44 - loss: 0.6931 - accuracy: 0.5260"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 7/10 [====================\u003e.........] - ETA: 2:48 - loss: 0.6934 - accuracy: 0.5179"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 8/10 [=======================\u003e......] - ETA: 1:51 - loss: 0.6937 - accuracy: 0.5117"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 9/10 [==========================\u003e...] - ETA: 56s - loss: 0.6935 - accuracy: 0.5139 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.4969 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - 725s 73s/step - loss: 0.6944 - accuracy: 0.4969 - val_loss: 0.6926 - val_accuracy: 0.5156\n","Epoch 4/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\r 1/10 [==\u003e...........................] - ETA: 10:06 - loss: 0.6918 - accuracy: 0.5312"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 2/10 [=====\u003e........................] - ETA: 7:28 - loss: 0.6928 - accuracy: 0.5000 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 3/10 [========\u003e.....................] - ETA: 6:29 - loss: 0.8691 - accuracy: 0.4792"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 4/10 [===========\u003e..................] - ETA: 5:35 - loss: 0.8247 - accuracy: 0.4922"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 5/10 [==============\u003e...............] - ETA: 4:40 - loss: 0.7972 - accuracy: 0.5125"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 6/10 [=================\u003e............] - ETA: 3:44 - loss: 0.7842 - accuracy: 0.5000"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 7/10 [====================\u003e.........] - ETA: 2:48 - loss: 0.7706 - accuracy: 0.5179"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 8/10 [=======================\u003e......] - ETA: 1:52 - loss: 0.7606 - accuracy: 0.5195"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 9/10 [==========================\u003e...] - ETA: 56s - loss: 0.7553 - accuracy: 0.5035 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.5125 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - 730s 74s/step - loss: 0.7490 - accuracy: 0.5125 - val_loss: 0.6951 - val_accuracy: 0.5063\n","Epoch 5/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\r 1/10 [==\u003e...........................] - ETA: 9:29 - loss: 0.6877 - accuracy: 0.5312"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 2/10 [=====\u003e........................] - ETA: 7:42 - loss: 0.7041 - accuracy: 0.5000"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 3/10 [========\u003e.....................] - ETA: 6:36 - loss: 0.6992 - accuracy: 0.5312"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 4/10 [===========\u003e..................] - ETA: 5:38 - loss: 0.6995 - accuracy: 0.5156"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 5/10 [==============\u003e...............] - ETA: 4:43 - loss: 0.6988 - accuracy: 0.4938"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 6/10 [=================\u003e............] - ETA: 3:46 - loss: 0.6995 - accuracy: 0.4948"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 7/10 [====================\u003e.........] - ETA: 2:50 - loss: 0.6983 - accuracy: 0.5045"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 8/10 [=======================\u003e......] - ETA: 1:54 - loss: 0.6991 - accuracy: 0.5000"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r 9/10 [==========================\u003e...] - ETA: 57s - loss: 0.6979 - accuracy: 0.5104 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - ETA: 0s - loss: 0.6974 - accuracy: 0.5125 "]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"name":"stdout","output_type":"stream","text":["\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\r10/10 [==============================] - 729s 74s/step - loss: 0.6974 - accuracy: 0.5125 - val_loss: 0.6961 - val_accuracy: 0.4719\n"]}],"source":["hist=model.fit_generator(steps_per_epoch=10, generator=traindata,\n","                         validation_data=testdata, validation_steps=10,\n","                         epochs=5,callbacks=[checkpoint,earlystop])"]},{"cell_type":"markdown","metadata":{"id":"_7ckzL5vT45u"},"source":["# **Prediction of test data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ur-9Z0BeiWOf"},"outputs":[],"source":["img=tf.keras.utils.load_img(\"/content/test_set/cats/cat.4012.jpg\",target_size=(224,224))\n","img=np.asarray(img)\n","plt.imshow(img)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLBe5X8EiX1m"},"outputs":[],"source":["img=np.expand_dims(img,axis=0)\n","saved_model=load_model(\"vgg16_1.h5\")\n","output =saved_model.predict(img)\n","if output[0][0]\u003eoutput[0][1]:\n","  print(\"cat\")\n","else:\n","  print(\"dog\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdqmZO8U0zuI"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOfn9ekY3NRUN1hjrBPqBSP","mount_file_id":"1ahKQ9rnStTk6ZwVBbMHViEfe6hGommNS","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}