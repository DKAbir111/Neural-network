{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9f04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8095a18",
   "metadata": {},
   "source": [
    "# 1. Load and normalize CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78e2747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform= transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfef1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ee25f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data',train=True,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa38417",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000bd1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddfde61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6fe71ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data',train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6702b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66fe372e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bc7a7",
   "metadata": {},
   "source": [
    "# 2. Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d78db034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without using sequential layer\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1= nn.Conv2d(3,6,5)\n",
    "        self.bn1=nn.BatchNorm2d(6)\n",
    "        self.conv2= nn.Conv2d(6,16,5)\n",
    "        self.bn2=nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.fc1= nn.Linear(16*5*5, 120) # 5*5 from image dimension\n",
    "        self.bn3=nn.BatchNorm1d(120)\n",
    "        self.fc2= nn.Linear(120,84)\n",
    "        self.bn4=nn.BatchNorm1d(84)\n",
    "        self.fc3= nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x=self.conv1(input)\n",
    "        x=F.relu(x)\n",
    "        x=F.max_pool2d(x,(2,2))\n",
    "        x=self.bn1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=F.relu(x)\n",
    "        x=F.max_pool2d(x,(2,2))\n",
    "        x=self.bn2(x)\n",
    "        \n",
    "        x= torch.flatten(x,1)\n",
    "        x=self.fc1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.fc2(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.bn4(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e18b8f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (bn3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (bn4): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model= Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aebee514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sequential layer\n",
    "#conv/FC -> Batchnorm -> activation func -> Pooling -> dropuout -> FC\n",
    "class Net1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers= nn.Sequential(\n",
    "        nn.Conv2d(3,6,5), \n",
    "        nn.BatchNorm2d(6),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "        \n",
    "        nn.Conv2d(6,16,5),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "            \n",
    "        nn.Flatten(1),\n",
    "            \n",
    "        nn.Linear(16*5*5, 120),\n",
    "        nn.BatchNorm1d(120),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "            \n",
    "        nn.Linear(120,84),\n",
    "        nn.BatchNorm1d(84),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        \n",
    "        nn.Linear(84,10)\n",
    "         \n",
    "        )\n",
    "       \n",
    "               \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb830cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (10): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.2, inplace=False)\n",
      "    (13): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (14): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): ReLU()\n",
      "    (16): Dropout(p=0.2, inplace=False)\n",
      "    (17): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net1()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9284950",
   "metadata": {},
   "source": [
    "# 3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29dffd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01,  weight_decay=0.01)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001) L1 regularization\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9) L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eed27c",
   "metadata": {},
   "source": [
    "# 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a3d8465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss:1.909\n",
      "epoch: 2 loss:1.774\n",
      "Finished training of 50000 images (12500 batches)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    total_loss=0.0\n",
    "    i=0\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred= model(inputs)\n",
    "        loss=criterion(pred,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() #per epoch\n",
    "        \n",
    "    print(f'epoch: {epoch+1} loss:{total_loss/i:.3f}')\n",
    "            \n",
    "    \n",
    "print(\"Finished training of 50000 images (12500 batches)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831e886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n"
     ]
    }
   ],
   "source": [
    "print(i) #batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36495cc2",
   "metadata": {},
   "source": [
    "# 5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5509a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0.0\n",
    "total=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37e57a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.0\n",
      "3809.0\n",
      "Accuracy of 10000 images(2500 batches): 38.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs= model(images)\n",
    "        _, pred= torch.max(outputs.data,1)\n",
    "        total+= labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    print(total)\n",
    "    print(correct)\n",
    "print(f'Accuracy of 10000 images(2500 batches): {100 * correct // total} %')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158e432",
   "metadata": {},
   "source": [
    "# 6. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1c1f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef6171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
